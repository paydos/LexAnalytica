import streamlit as st

from utils.acknowledge import show_creator_acknowledgement
from utils.pwd import check_password

st.set_page_config(
    page_title="LexAnalytica",
    page_icon="data/branded_icon.png",
    layout="wide",
    initial_sidebar_state="collapsed",
)


col1, col2, col3, col4, col5, col6 = st.columns([2, 2, 2, 2, 3, 2])
L, R = st.columns(2, gap="medium")

with col2:
    st.title(
        "About üìò",
    )

with L:
    st.subheader("Configuraci√≥n y Uso de LexAnalytica")
    st.markdown(
        """
        Para explicar c√≥mo se ha configurado y utilizado la IA LexAnalytica para responder a preguntas de tests de acceso a la abogac√≠a, describir√© los distintos componentes y decisiones tomadas en el proceso.
    """,
        unsafe_allow_html=True,
    )

    st.subheader("Uso de la Vector Store y ajuste de par√°metros:")
    st.markdown(
        """
        - **Vector Store**: Para garantizar la m√°xima precisi√≥n y relevancia de los datos, se ha procedido a la carga del Vector Store con legislaci√≥n y material doctrinal de suma importancia, optando deliberadamente por una operaci√≥n desconectada de la red global de Internet. Esta decisi√≥n se fundamenta en la exploraci√≥n exhaustiva de las posibilidades que ofrece el acceso a Internet, concluyendo que su uso podr√≠a comprometer la integridad y especificidad de la informaci√≥n al introducir potenciales errores derivados de fuentes no verificadas.
        - **Temperatura de generaci√≥n**: La configuraci√≥n de la temperatura de generaci√≥n se ha establecido en 0.15, con el objetivo de restringir la variabilidad en las respuestas generadas por el sistema y minimizar la generaci√≥n de contenido no basado en datos fiables. Esta medida refuerza la determinaci√≥n y precisi√≥n de las respuestas, elementos cr√≠ticos en el √°mbito jur√≠dico, donde la exactitud y la fiabilidad son imperativas.
    """,
        unsafe_allow_html=True,
    )

    st.subheader("Protocolos de Elaboraci√≥n de Respuestas:")
    st.markdown(
        """
        Hemos implementado un conjunto de protocolos meticulosamente definidos para la elaboraci√≥n de respuestas. Estos protocolos permiten al sistema realizar un an√°lisis l√≥gico y fundamentado para determinar la veracidad de cada opci√≥n presentada en los tests, bas√°ndose en pilares jur√≠dicos robustos como la legislaci√≥n vigente, la jurisprudencia relevante y la doctrina establecida.
    """,
        unsafe_allow_html=True,
    )

    st.subheader("Configuraci√≥n Avanzada del FusionRAG:")
    st.markdown(
        """
        - **Par√°metros de B√∫squeda**: Optamos por una configuraci√≥n de 5x5 en el FusionRAG, aprovechando al m√°ximo el l√≠mite permitido. Esta configuraci√≥n estrat√©gica posibilita la exploraci√≥n exhaustiva de la informaci√≥n disponible para cada consulta, garantizando una cobertura integral y minuciosa de las cuestiones jur√≠dicas pertinentes.
        - **Contextualizaci√≥n de Consultas**: La preparaci√≥n del contexto para las interacciones con el FusionRAG se ha dise√±ado meticulosamente para convertir las interrogantes de los usuarios en consultas especializadas que maximicen la eficacia de la b√∫squeda en la Vector Store. Esto se logra mediante la identificaci√≥n precisa de los temas clave, bas√°ndose en la categor√≠a jur√≠dica correspondiente y la formulaci√≥n de consultas de b√∫squeda altamente espec√≠ficas.
    """,
        unsafe_allow_html=True,
    )

    st.subheader("Estructuraci√≥n y Redacci√≥n del Prompt para GPT-4:")
    st.markdown(
        """
        La estructura y redacci√≥n del prompt se han cuidadosamente elaborado para dirigir al modelo de inteligencia artificial GPT-4 hacia la generaci√≥n de respuestas que no solo determinen la opci√≥n correcta, sino que tambi√©n proporcionen una justificaci√≥n exhaustiva de esta elecci√≥n, respaldada por referencias espec√≠ficas a legislaci√≥n, jurisprudencia y doctrina.
    """,
        unsafe_allow_html=True,
    )

    st.markdown(
        """
        En resumen, estamos convencidos de que este enfoque meticuloso asegura que el agente de inteligencia artificial ofrezca respuestas bien fundamentadas y precisas, reflejando una comprensi√≥n profunda de las materias legales pertinentes y las competencias anal√≠ticas esenciales para el ejercicio de la abogac√≠a. Cada componente ha sido cuidadosamente ajustado para optimizar la exactitud y pertinencia de las respuestas en el marco del Examen de Acceso a la Abogac√≠a.
    """,
        unsafe_allow_html=True,
    )
with col5:
    st.title("Arquitectura üõ†Ô∏è")

with R:
    with st.expander("üìê Diagrama de Arquitectura"):
        st.image("data/archHackathon.png")
    with st.expander("# üõ†Ô∏è Tech Stack"):
        st.markdown(
            """
    - **Lenguaje de Programaci√≥n:** Python üêç
    - **Interfaz de Usuario:** Streamlit
    - **Modelos de Lenguaje:** OpenAI
    - **Gesti√≥n de Embeddings:** Pinecone
    - **Framework de Desarrollo:** LangChain ü¶ú
    """
        )

    st.subheader("Backend")
    st.write(
        """
        La arquitectura de backend de nuestro sistema se fundamenta completamente en Python, con un enfoque full-stack para el desarrollo de LexAnalytica. Inicialmente, valoramos la implementaci√≥n de un modelo de Hugging Face open-source; sin embargo, las restricciones inherentes a la infraestructura de este servidor nos llevaron a optar por la plataforma OpenAI ya que nos ofrecen una base s√≥lida para nuestro proyecto. Aunque consideramos alternativas como AnthropicsAI, decidimos tirar por OpenAI ya que no vimos mejoras que justificasen el cambio.
        """
    )
    st.subheader("RAGs y Embeddings")
    st.write(
        """
        Buscando optimizar nuestro Modelo de Lenguaje de Gran Escala (LLM), inicialmente implementamos una soluci√≥n basada en RAG (Retrieval-Augmented Generation) on-premise, con el modelo intfloat/e5-base-v2. A pesar de que los resultados iniciales fueron prometedores, la precisi√≥n en la conversi√≥n pregunta-embeddings por parte del RAG result√≥ insuficiente. Esto nos llev√≥ a adoptar Fusion-RAG, una variante avanzada que integra otro LLM especializado para mejorar la generaci√≥n de respuestas contextualmente relevantes y precisas, logrando as√≠ un rendimiento significativamente superior.

        Nos inspiramos en el trabajo de investigaci√≥n arXiv:2402.03367, donde se explora las implicaciones y beneficios de esta tecnolog√≠a en el campo de AI & LLM.
        """
    )
    st.subheader("Vector Databse")
    st.write(
        """
        Para enriquecer la capacidad de respuesta de LexAnalytica, hemos incorporado un Vector Store con una colecci√≥n de legislaci√≥n del BOE, junto con una variedad de documentos como res√∫menes y ex√°menes corregidos. Por conveniencia, hemos optado por la infraestructura de Pinecone, donde alojamos nuestros embeddings, facilitando as√≠ un acceso r√°pido y seguro a la informaci√≥n.
        """
    )

show_creator_acknowledgement()
